{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InterpretableSAD_BGL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "14JLvY9PBHV0"
      },
      "source": [
        "# Install captum package\r\n",
        "!pip install captum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J9A0V63qLeW"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "from utils import preprocessing, SlidingWindow, NegativeSampling, utils, model, explain\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from tqdm import tqdm\r\n",
        "import time\r\n",
        "import math\r\n",
        "import os\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.metrics import precision_recall_fscore_support\r\n",
        "from captum.attr import LayerIntegratedGradients\r\n",
        "import collections"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7vbfwlP8IfJ"
      },
      "source": [
        "DATASET_NAME = 'BGL'\r\n",
        "TRAIN_SIZE = 100000\r\n",
        "WINDOW_SIZE = 100\r\n",
        "STEP_SIZE = 20\r\n",
        "RATIO = 0.1\r\n",
        "SEED = 42"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yerXXxqJqetY"
      },
      "source": [
        "# Download dataset and parsing the dataset with Drain\r\n",
        "preprocessing.parsing(DATASET_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERsjmU1r5Zo9"
      },
      "source": [
        "# Cut log data into sliding windows\r\n",
        "# Split data into training normal dataset, test normal dataset, and test abnormal dataset\r\n",
        "# Get the bigram from training normal dataset\r\n",
        "# Train a Word2Vec model with the training normal data\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "train_normal, test_normal, test_abnormal, bigram, unique, weights, train_dict, w2v_dic = SlidingWindow.sliding(DATASET_NAME, WINDOW_SIZE, STEP_SIZE, TRAIN_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSsRoGViaEpG"
      },
      "source": [
        "# +1 for unknown\r\n",
        "VOCAB_DIM = len(train_dict)+1\r\n",
        "OUTPUT_DIM = 2\r\n",
        "EMB_DIM = 8\r\n",
        "HID_DIM = 128\r\n",
        "N_LAYERS = 1\r\n",
        "DROPOUT = 0.0\r\n",
        "BATCH_SIZE = 32\r\n",
        "TIMES = 20"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8HIfgwvblO5"
      },
      "source": [
        "# Get negative samples and split into training data and val data\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "neg_samples = NegativeSampling.negative_sampling(train_normal, bigram, unique, TIMES, VOCAB_DIM)\r\n",
        "df_neg = utils.get_dataframe(neg_samples, 1, w2v_dic)\r\n",
        "df_pos = utils.get_dataframe(list(train_normal['EventId']), 0, w2v_dic)\r\n",
        "df_pos.columns = df_pos.columns.astype(str)\r\n",
        "df_train = pd.concat([df_pos, df_neg], ignore_index = True, axis=0)\r\n",
        "df_train.reset_index(drop = True)\r\n",
        "y = list(df_train.loc[:,'class_label'])\r\n",
        "X = list(df_train['W2V_EventId'])\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
        "X_train = torch.tensor(X_train,requires_grad=False).long()\r\n",
        "X_val = torch.tensor(X_val,requires_grad=False).long()\r\n",
        "y_train = torch.tensor(y_train).reshape(-1, 1).long()\r\n",
        "y_val = torch.tensor(y_val).reshape(-1, 1).long()\r\n",
        "train_iter = utils.get_iter(X_train, y_train, BATCH_SIZE)\r\n",
        "val_iter = utils.get_iter(X_val, y_val, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUEk54oerMa5"
      },
      "source": [
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True\r\n",
        "\r\n",
        "device = torch.device( \"cuda\" if torch.cuda.is_available() else\"cpu\")\r\n",
        "interpretableSAD = model.C_lstm(weights, VOCAB_DIM, OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, device, BATCH_SIZE).to(device)\r\n",
        "print(f'The model has {model.count_parameters(interpretableSAD):,} trainable parameters')\r\n",
        "print()\r\n",
        "optimizer = optim.Adam(interpretableSAD.parameters())\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "try:\r\n",
        "    os.makedirs('Model')\r\n",
        "except:\r\n",
        "    pass\r\n",
        "\r\n",
        "#Training interpretableSAD\r\n",
        "N_EPOCHS = 10\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_test_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in tqdm(range(N_EPOCHS)):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    train_loss= model.train(interpretableSAD, train_iter, optimizer, criterion, CLIP, epoch, device)        \r\n",
        "\r\n",
        "    val_loss = model.evaluate(interpretableSAD, val_iter, criterion, device)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = model.epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if val_loss < best_test_loss:\r\n",
        "        best_test_loss = val_loss\r\n",
        "        torch.save(interpretableSAD.state_dict(), 'Model/interpretableSAD_BGL.pt')\r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. PPL: {math.exp(val_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqf2XgeQvFNs"
      },
      "source": [
        "# less or equal than 10% abnormal data\r\n",
        "test_abnormal_ratio = model.ratio_abnormal_sequence(test_abnormal, WINDOW_SIZE, RATIO)\r\n",
        "test_ab_X, test_ab_X_key_label = test_abnormal_ratio['W2V_EventId'], test_abnormal_ratio['Key_label']\r\n",
        "test_n_X, test_n_X_key_label = test_normal['W2V_EventId'], test_normal['Key_label']\r\n",
        "test_ab_y = test_abnormal_ratio['Label']\r\n",
        "test_n_y = test_normal['Label']\r\n",
        "y, y_pre = model.model_precision(interpretableSAD, device, test_n_X.values.tolist()[:int(len(test_n_X.values.tolist())*(len(test_abnormal_ratio)/len(test_abnormal)))], \\\r\n",
        "                           test_ab_X.values.tolist())\r\n",
        "f1_acc = metrics.classification_report(y, y_pre, digits=5)\r\n",
        "print(f1_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INJMc36h833C"
      },
      "source": [
        "lig = LayerIntegratedGradients(interpretableSAD, interpretableSAD.embedding)\r\n",
        "lst_train_keys = []\r\n",
        "for i in train_normal.W2V_EventId.values:\r\n",
        "    lst_train_keys.extend(i)\r\n",
        "dic_app = collections.Counter(lst_train_keys)\r\n",
        "if w2v_dic[str(len(train_dict))] not in dic_app.keys():\r\n",
        "    dic_app[w2v_dic[str(len(train_dict))]] = 0\r\n",
        "start = [w2v_dic[i] for i in unique]\r\n",
        "lst_attr, lst_y, lst_dist, lst_keys, lst_baseline = explain.get_dataset(interpretableSAD, device, lig, test_ab_X, test_ab_X_key_label, dic_app, start, RATIO, WINDOW_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbxcecdrK2Qp"
      },
      "source": [
        "exp_df = pd.DataFrame()\r\n",
        "exp_df['key'] = lst_keys\r\n",
        "exp_df['attr'] = lst_attr\r\n",
        "exp_df['y'] = lst_y\r\n",
        "exp_df['baseline'] = lst_baseline\r\n",
        "best_inter = explain.get_mean_inter(exp_df)\r\n",
        "# Zero as inter\r\n",
        "mean_pred = explain.mean_inter(exp_df)\r\n",
        "print(\"Accuracy for zero inter:\",metrics.accuracy_score(lst_y, mean_pred))\r\n",
        "print(metrics.classification_report(lst_y, mean_pred, digits=5))\r\n",
        "# Best inter\r\n",
        "mean_pred = explain.mean_inter(exp_df, interception=best_inter)\r\n",
        "print(\"Accuracy for the best inter:\",metrics.accuracy_score(lst_y, mean_pred))\r\n",
        "print(metrics.classification_report(lst_y, mean_pred, digits=5))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}